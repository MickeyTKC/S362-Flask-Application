# Full name and 8-digit student number
- Name: Tse Kai Chun
- Student number: 12755669

# Files
- `legacy_pi_server.Py`: Legacy server code uses primitive π calculation technology.
- `s12755669_server.Py`: API Flask server code that provides endpoints for π calculation and user statistics.
- `s12755669_test.Py`: Unit test code used to verify Flask server functionality.
- `s12755669_client.Py`: Testing specific functionality and output from interaction with the server.

# Instructions for putting in place server application
### Libraries
- `os`: For interacting with the running machine.
- `time` and `timeit`: For measuring execution time.
- `Flask`: A web framework for constructing the API.
- `random`: For generating random numbers inside the Monte Carlo simulation.
- `threading.Lock()`: For coping with concurrent connections within the Statistics carrier (Read File, Write File).
- `concurrent.Futures`: For using `ProcessPoolExecutor` and `ThreadPoolExecutor`.
- `socket`: For handling TCP and UDP connections.
- `regex`: For advanced string matching and validation.

# Instructions for putting in take a look at application
### Libraries
- `os`: For running machine interactions.
- `subprocess`: For executing subprocesses.
- `unittest`: For structuring and strolling assessments.
- `time`: For measuring time throughout assessments.
- `json`: For handling JSON statistics in requests and responses.
- `requests`: For making HTTP requests to the API.


# JSON format of the Statistics web service 
- Example: 
```json
[
  {"request_count": 10, "username": "1111"},
  {"request_count": 10, "username": "2222"}
]
```

# Description and Justification of the Concurrency Solutions in the Pi and Legacy Pi Web Services

The Pi and Legacy Pi services in `s12755669_server.py` utilize concurrency to efficiently calculate π (Pi) using different methods, enhancing performance and user experience by allowing the server to handle multiple requests simultaneously.

## 1. Pi Service

The Pi service implements the Monte Carlo method to calculate π. Key features of its concurrent solutions include:

- **Process Pooling** 
  - Uses `ProcessPoolExecutor` to distribute workload across multiple processes, leveraging multi-core processors.

- **Scalability**: 
  - Manages increased requests without significant response time delays by allocating more processes as needed.

- **Responsiveness**: 
  - Reduces execution time for high simulation counts, providing quicker results to users.

- **Error Handling**: 
  - Allows graceful management of failures in individual processes, enhancing overall system reliability.

### Implementation Overview

When a request is obtained at the `/pi` endpoint:
- Input parameters are validated.
- Total simulations are divided by the required concurrency degree.
- Simulations are run in parallel the usage of `ProcessPoolExecutor`.
- Results are aggregated to provide the final π estimate.

## 2. Legacy Pi Service

Legacy Pi services use traditional network protocols (TCP and UDP) to calculate π. Its concurrency solutions focus on efficiently handling multiple network requests:

- **Protocol Support**: 
  - Supports both TCP and UDP, allowing flexibility in how to query π calculations.

- **Process Pooling:** 
  - Uses `ProcessPoolExecutor` to distribute workloads across multiple processes, taking advantage of multi-core processors.

- **Responsiveness**: 
  - Provides fast responses for customers, regardless of the protocol used, maintaining low latency.

- **Load Balancing**: 
  - Distribute requests to available threads, optimizing resource utilization and improving throughput.

### Implementation Overview

When a request is made to the `/legacy_pi` endpoint:
- The server determines the protocol (TCP or UDP).
- For TCP, a connection is established, and records is despatched/received the use of sockets.
- For UDP, data is despatched with out setting up a connection.
- Responses are generated based totally at the calculations finished in parallel.

# Discussion on Adopting Advanced Technologies in Server Programming

## Introduction
To enhance server performance and scalability, adopting advanced technologies is essential. This discussion highlights key concepts from asynchronous programming, high-performance computing, and profiling techniques.

## 1. Asynchronous Programming
Asynchronous programming is vital for responsive server applications, allowing them to handle multiple requests concurrently.

- **Benefits:**
  - **Non-blocking I/O:** Libraries like `asyncio` enable servers to manage many connections simultaneously.
  - **Resource Efficiency:** Tasks can yield during I/O operations, allowing the server to process other requests.

- **Applications:**
  - Asynchronous frameworks (e.g., FastAPI) are ideal for high-traffic web APIs and real-time applications.

## 2. High-Performance Computing (HPC)
HPC techniques improve performance in data-intensive server applications.

- **Native Code Libraries:** Use libraries like NumPy and TensorFlow for efficient numerical and machine learning tasks.
- **Native Modules:** Tools like Cython can compile critical Python code into native code for speed.
- **Concurrency Models:** Multiprocessing and MPI enable distribution of workloads across CPUs or machines.

## 3. Profiling and Optimization
Profiling helps identify performance bottlenecks in server applications.

- **Tools:** Use `cProfile` to generate detailed reports on function performance.
- **Best Practices:** Optimize after ensuring correctness, focusing on the most time-consuming functions.

## 4. Message Passing in Distributed Servers
The Message Passing Interface (MPI) is crucial for communication in distributed server architectures.

- **SPMD Model:** Allows multiple processes to execute the same program with different data, improving computational efficiency.
- **Integration with Python:** The `mpi4py` library facilitates efficient data communication between processes.

## Conclusion
Adopting asynchronous programming, HPC techniques, and profiling methods is key to developing robust server applications. By leveraging these strategies, developers can create scalable and efficient solutions that meet user demands.