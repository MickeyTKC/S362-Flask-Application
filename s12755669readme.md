# Full name and 8-digit student number
- Name: Tse Kai Chun
- Student number: 12755669

# Files
- `legacy_pi_server.py`: The legacy server code implementing the original π calculation method.
- `s12755669_server.py`: The API Flask server code that provides endpoints for π calculations and user statistics.
- `s12755669_test.py`: The unit test code for validating the functionality of the Flask server.
- `s12755669_client.py`: The client code for testing specific functions with output to interact with the server.

# Instructions for setting up server program
### Libraries
- `os`: For interacting with the operating system.
- `time` and `timeit`: For measuring execution time.
- `Flask`: A web framework for building the API.
- `random`: For generating random numbers in the Monte Carlo simulation.
- `threading.Lock()`: For managing concurrent connections in the Statistics service (Read File, Write File).
- `concurrent.futures`: For using `ProcessPoolExecutor` and `ThreadPoolExecutor`.
- `socket`: For handling TCP and UDP connections.
- `regex`: For advanced string matching and validation.

# Instructions for setting up test program
### Libraries
- `os`: For operating system interactions.
- `subprocess`: For executing subprocesses.
- `unittest`: For structuring and running tests.
- `time`: For measuring time during tests.
- `json`: For handling JSON data in requests and responses.
- `requests`: For making HTTP requests to the API.

# JSON format of the Statistics web service 
- Example: 
```json
[
  {"request_count": 10, "username": "1111"},
  {"request_count": 10, "username": "2222"}
]
```

# Description and Justification of the Concurrency Solutions in the Pi and Legacy Pi Web Services

The Pi and Legacy Pi services in `s12755669_server.py` utilize concurrency to efficiently calculate π (Pi) using different methods, enhancing performance and user experience by allowing the server to handle multiple requests simultaneously.

## 1. Pi Service (`#R1`)

The Pi service implements the Monte Carlo method for π calculation. Key features of its concurrency solution include:

- **CPU Utilization**: 
  - Uses `ProcessPoolExecutor` to distribute workload across multiple processes, leveraging multi-core processors.

- **Scalability**: 
  - Manages increased requests without significant response time delays by allocating more processes as needed.

- **Responsiveness**: 
  - Reduces execution time for high simulation counts, providing quicker results to users.

- **Error Handling**: 
  - Allows graceful management of failures in individual processes, enhancing overall system reliability.

### Implementation Overview

When a request is received at the `/pi` endpoint:
- Input parameters are validated.
- Total simulations are divided by the specified concurrency level.
- Simulations are run in parallel using `ProcessPoolExecutor`.
- Results are aggregated to provide the final π estimate.

## 2. Legacy Pi Service (`#R2`)

The Legacy Pi service calculates π using traditional network protocols (TCP and UDP). Its concurrency solution focuses on handling multiple network requests efficiently:

- **Protocol Support**: 
  - Supports both TCP and UDP, allowing flexibility in how π calculations are requested.

- **Threading**: 
  - Uses threading to manage concurrent connections, enabling the server to handle multiple clients simultaneously without blocking.

- **Responsiveness**: 
  - Provides quick feedback to clients regardless of the protocol used, maintaining low latency.

- **Load Balancing**: 
  - Distributes requests across available threads, optimizing resource use and improving throughput.

### Implementation Overview

When a request is made to the `/legacy_pi` endpoint:
- The server determines the protocol (TCP or UDP).
- For TCP, a connection is established, and data is sent/received using sockets.
- For UDP, data is sent without establishing a connection.
- Responses are generated based on the calculations performed in parallel.

# Discussion on Adopting Advanced Technologies in Server Programming

## Introduction
To enhance server performance and scalability, adopting advanced technologies is essential. This discussion highlights key concepts from asynchronous programming, high-performance computing, and profiling techniques.

## 1. Asynchronous Programming
Asynchronous programming is vital for responsive server applications, allowing them to handle multiple requests concurrently.

- **Benefits:**
  - **Non-blocking I/O:** Libraries like `asyncio` enable servers to manage many connections simultaneously.
  - **Resource Efficiency:** Tasks can yield during I/O operations, allowing the server to process other requests.

- **Applications:**
  - Asynchronous frameworks (e.g., FastAPI) are ideal for high-traffic web APIs and real-time applications.

## 2. High-Performance Computing (HPC)
HPC techniques improve performance in data-intensive server applications.

- **Native Code Libraries:** Use libraries like NumPy and TensorFlow for efficient numerical and machine learning tasks.
- **Native Modules:** Tools like Cython can compile critical Python code into native code for speed.
- **Concurrency Models:** Multiprocessing and MPI enable distribution of workloads across CPUs or machines.

## 3. Profiling and Optimization
Profiling helps identify performance bottlenecks in server applications.

- **Tools:** Use `cProfile` to generate detailed reports on function performance.
- **Best Practices:** Optimize after ensuring correctness, focusing on the most time-consuming functions.

## 4. Message Passing in Distributed Servers
The Message Passing Interface (MPI) is crucial for communication in distributed server architectures.

- **SPMD Model:** Allows multiple processes to execute the same program with different data, improving computational efficiency.
- **Integration with Python:** The `mpi4py` library facilitates efficient data communication between processes.

## Conclusion
Adopting asynchronous programming, HPC techniques, and profiling methods is key to developing robust server applications. By leveraging these strategies, developers can create scalable and efficient solutions that meet user demands.